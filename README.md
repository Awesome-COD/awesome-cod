<p align="center">
    <img src="./imgs/Logo.png"/> <br />
</p>

<p align="center">
    <img src="https://img.shields.io/badge/-As%20awesome%20as%20you%20think!-red" alt="Awesome Badge">
    <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License: MIT">
    <img src="https://img.shields.io/github/last-commit/Awesome-COD/awesome-cod" alt="GitHub last commit">
</p>

# <p align=center>`Awesome List for Camouflaged Object Detection (COD)`

<details>
<summary>:loudspeaker:<strong>Last updated: 2025.09.30</strong></summary>

- [09/2025] Update with ACMMM2025 and latest papers. 
- [06/2025] Update with ICCV2025 papers.    
- [06/2025] Update with CVPR2025, AAAI2025 papers.    
</details>

---

:teddy_bear: We mark different tasks with coloured squares:

<table>
    <tr>
        <td style="width: 20%;">:blue_square:<code>COD</code></td>
        <td style="width: 20%;">Camouflaged Object Detection</td>
        <td style="width: 20%;">:orange_square:<code>COS</code></td>
        <td style="width: 20%;">Camouflaged Object Segmentation</td>
    </tr>
    <tr>
        <td style="width: 20%;">:green_square:<code>CG</code></td>
        <td style="width: 20%;">Camouflage Generation</td>
        <td style="width: 20%;">:red_square:<code>VCOD</code></td>
        <td style="width: 20%;">Video Camouflaged Object Detection</td>
    </tr>
    <tr>
        <td style="width: 20%;">:purple_square:<code>COT</code></td>
        <td style="width: 20%;">Camouflaged Object Tracking</td>
        <td style="width: 20%;">:white_large_square:<code>CX</code></td>
        <td style="width: 20%;">Other types of Camouflage Task</td>
    </tr>
</table>

---

<!--TOC-->

## ðŸ“š Table of Contents:
<!-- - [Overview](#Overview) -->
<table style="margin-left: auto; margin-right: auto;">
    <tr>
        <td> <!--å·¦ä¾§å†…å®¹-->
            <ul>
                <li><a href="#1-Latest">1. Latest Work</a></li>
                <li><a href="#2-Survey-Papers">2. Survey Papers</a></li>
                <li><a href="#3-Image-Camouflage-Detection">3. Image Camouflage Detection</a>
                    <ul>
                        <li><a href="#31-COD">3.1. Camouflaged Object Detection (COD)</a></li>
                        <li><a href="#32-Semi-supervised-COD">3.2. Semi-supervised COD</a></li>
                        <li><a href="#33-Weakly-supervised-COD">3.3. Weakly-supervised COD</a></li>
                        <li><a href="#34-Unsupervised-COD">3.4. Unsupervised COD</a></li>
                        <li><a href="#35-Referring-COD">3.5. Referring COD</a></li>
                        <li><a href="#36-Zero-Shot-COD">3.6. Zero-Shot COD</a></li>
                        <li><a href="#37-Multispectral-COD">3.7. Multispectral COD</a></li>
                        <li><a href="#38-Polarized-COD">3.8. Polarized COD</a></li>
                    </ul>
                </li>
            </ul>
        </td>
        <td> <!--å³ä¾§å†…å®¹-->
            <ul>
                <li><a href="#4-Video-Camouflage-Detection">4. Video Camouflage Detection</a>
                    <ul>
                         <li><a href="#41-Video-Camouflaged-Object-Detection">4.1. Video Camouflaged Object Detection (VCOD)</a></li>
                    </ul>
                </li>
                <li><a href="#5-Camouflage-Segmentation">5. Camouflage Segmentation</a>
                    <ul>
                        <li><a href="#51-Camouflage-Object-Segmentation">5.1. Camouflage Object Segmentation (COS)</a>
                        <li><a href="#52-Camouflaged-Instance-Segmentation">5.2. Camouflaged Instance Segmentation (CIS)</a></li>
                        <li><a href="#53-Open-Vocabulary-COS">5.3. Open-Vocabulary COS</a></li>
                    </ul>
                </li>
                <li><a href="#6-Camouflage-Generation">6. Camouflage Generation</a></li>
                <li><a href="#7-Camouflage-Tracking">7. Camouflage Tracking</a></li>
                <li><a href="#8-Other-Related">8. Other Related</a></li>
                <li><a href="#Datasets">Datasets</a></li>
                <li><a href="#Reference">Reference</a></li>
            </ul>
        </td>
    </tr>
</table>

----------------------------------------------------------------------------------------------------------------------

<h2 id="1-Latest">
    <span>:fire: 1. Latest Work (Last 6 months)</span>
</h2>

| **Task** | **Release** |**Pub.** | **Title** | **Links** |
| :------: | :---------: | :-----: | :-------: | :-------: |
|:white_large_square: `XCOD` | `2023/Mar` | `Arxiv` | Explicit Visual Prompting for Universal Foreground Segmentations <br> <sup><sub>*Weihuang Liu, Xi Shen, Chi-Man Pun, Xiaodong Cun*</sub></sup> | [Paper](https://arxiv.org/abs/2305.18476) / [Code](https://github.com/NiFangBaAGe/Explicit-Visual-Prompt) |

----------------------------------------------------------------------------------------------------------------------

<details>
    <summary>
        <h2 id="2-Survey-Papers">
            <span>2. Survey Papers</span>
        </h2>
    </summary>
</details>

----------------------------------------------------------------------------------------------------------------------

<!--Image Camouflage Detection-->
<details>
    <summary><h2 id="3-Image-Camouflage-Detection"><span>3. Image Camouflage Detection</span></h2></summary>




<details>
    <summary><h3 id="31-COD"><span>3.1. Camouflaged Object Detection</span></h3></summary>  

    <details>
        <summary><h4>2026</h4></summary>

| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2026 | PR | `TG-COD` | Text-guided camouflaged object detection <br> <sup><sub>*Zefeng Chen, Yunqi Xue, Zhijiang Li, Philip Torr, Jindong Gu*</sub></sup> | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S0031320325007186)\|Code |

    </details>
    
</details>







<details>
    <summary><h3 id="32-COD"><span>3.2. Semi-supervised COD</span></h3></summary>    


| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2025 | TPAMI | `SEE`  | Segment Concealed Objects with Incomplete Supervision   <br> <sup><sub>*Chunming He, Kai Li, Yachao Zhang, Ziyun Yang, Youwei Pang, Longxiang Tang, Chengyu Fang, Yulun Zhang, Linghe Kong, Xiu Li, Sina Farsiu*</sub></sup>  | [Paper](https://arxiv.org/abs/2506.08955)\|[Code](https://github.com/ChunmingHe/SEE) 
| 2025 | ACMMM | `ST-SAM` | ST-SAM: SAM-Driven Self-Training Framework for Semi-Supervised Camouflaged Object Detection   <br> <sup><sub>*Xihang Hu, Fuming Sun, Jiazhe Liu, Feilong Xu, Xiaoli Zhang*</sub></sup>  | [Paper](https://arxiv.org/abs/2507.23307)\|[Code](https://github.com/hu-xh/ST-SAM)
| 2025 | ICASSP | `SILNet` | Semi-supervised Iterative Learning Network for Camouflaged Object Detection   <br> <sup><sub>*Guowen Yue; Ge Jiao; Jiahao Xiang*</sub></sup>  | [Paper](https://ieeexplore.ieee.org/document/10890224)\|Code
| 2024 | ACMMM | `-` | Semi-supervised Camouflaged Object Detection from Noisy Data  <br> <sup><sub>*Yuanbin Fu, Jie Ying, Houlei Lv, Xiaojie Guo*</sub></sup>  | [Paper](https://dl.acm.org/doi/abs/10.1145/3664647.3680645)\|Code 
| 2024 | ECCV | `CamoTeacher` | CamoTeacher: Dual-Rotation Consistency Learning for Semi-Supervised Camouflaged Object Detection  <br> <sup><sub>*Xunfa Lai, Zhiyu Yang, Jie Hu, Shengchuan Zhang, Liujuan Cao, Guannan Jiang, Zhiyu Wang, Songan Zhang, Rongrong Ji*</sub></sup>  | [Paper](https://arxiv.org/abs/2408.08050)\|Code
| 2024 | ECCV | `WSSCOD` | Learning Camouflaged Object Detection from Noisy Pseudo Label   <br> <sup><sub>*Jin Zhang, Ruiheng Zhang, Yanjiao Shi, Zhe Cao, Nian Liu, Fahad Shahbaz Khan*</sub></sup>  | [Paper](https://arxiv.org/abs/2407.13157)\|[Code](https://github.com/zhangjinCV/Noisy-COD) 
</details>



<details>
    <summary><h3 id="33-COD"><span>3.3. Weakly-supervised COD</span></h3></summary>    


| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2025 | TPAMI | `SEE` | Segment Concealed Objects with Incomplete Supervision   <br> <sup><sub>*Chunming He, Kai Li, Yachao Zhang, Ziyun Yang, Youwei Pang, Longxiang Tang, Chengyu Fang, Yulun Zhang, Linghe Kong, Xiu Li, Sina Farsiu*</sub></sup>  | [Paper](https://arxiv.org/abs/2506.08955)\|[Code](https://github.com/ChunmingHe/SEE)  
| 2025 | TIP | `MSST` | UpGen: Unleashing Potential of Foundation Models for Training-Free Camouflage Detection via Generative Models  <br> <sup><sub>*Ji Du; Jiesheng Wu; Desheng Kong; Weiyun Liang; Fangwei Hao; Jing Xu; Bin Wang; Guiling Wang; Ping Li*</sub></sup>  | [Paper](https://ieeexplore.ieee.org/abstract/document/11131534)\|Code  
| 2025 | ECAI | `FCT-SAM` | Scribble-based Weakly Supervised Camouflaged Object Detection via SAM-guided Feature Correlation Transformer  <br> <sup><sub>*Zi-Jie Wu, Rongrong Gao and Tian-Zhu Xiang*</sub></sup>  | Paper\|[Code](https://github.com/farewellIamLoser/FCT-SAM-WSCOD) 
| 2025 | NN | `LRDNet` | Long-range diffusion for weakly camouflaged object segmentation <br>   <sup><sub>*Rui Wang, Caijuan Shi, Weixiang Gao, Changyu Duan, Ao Cai, Fei Yu, Yunchao Wei*</sub></sup>  | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S0893608025007968)\|[Code](https://github.com/Ray3417/LRDNet)  
| 2025 | KBS | `PPL` | Weakly supervised camouflaged object detection as Progressive Perception Learning   <br> <sup><sub>*Tianxin Han, Xingwei Wang, Qing Dong, Min Huang, Jie Jia, Fu Zhang*</sub></sup>  | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S095070512501038X)\|[Code](https://github.com/NGI-vision/PPL) 
| 2025 | TCSVT | `SAM-COD+` | SAM-COD+: SAM-Guided Unified Framework for Weakly-Supervised Camouflaged Object Detection   <br> <sup><sub>*Huafeng Chen; Pengxu Wei; Guangqian Guo; Shan Gao*</sub></sup>  | [Paper](https://ieeexplore.ieee.org/document/10789225)\|Code  
| 2025 | CVIU | `SCNet` | Adaptive context mining for camouflaged object detection with scribble supervision   <br> <sup><sub>*Dongdong Zhang, Chunping Wang, Huiying Wang, Qiang Fu, Zhaorui Li*</sub></sup>  | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S1077314225001535)\|[Code](https://github.com/zcc0616/SCNet)  
| 2024 | MM | `MiNet` | MiNet: Weakly-Supervised Camouflaged Object Detection through Mutual Interaction between Region and Edge Cues   <br> <sup><sub>*Yuzhen Niu, Lifen Yang, Rui Xu, Yuezhou Li, Yuzhong Chen*</sub></sup>  | [Paper](https://dl.acm.org/doi/10.1145/3664647.3680891)\|Code 
| 2024 | ECCV | `WSSCOD` | Learning Camouflaged Object Detection from Noisy Pseudo Label  <br> <sup><sub>*Jin Zhang, Ruiheng Zhang, Yanjiao Shi, Zhe Cao, Nian Liu, Fahad Shahbaz Khan*</sub></sup>  | [Paper](https://arxiv.org/abs/2407.13157)\|Code 
| 2024 | ECCV | `SAM-COD` | SAM-COD: SAM-guided Unified Framework for Weakly-Supervised Camouflaged Object Detection     <br> <sup><sub>*Huafeng Chen, Pengxu Wei, Guangqian Guo, Shan Gao*</sub></sup>  | [Paper](https://www.arxiv.org/abs/2408.10760)\|[Code](https://github.com/2231122/SAM-COD)
| 2024 | ECCV | `-` | Just a Hint: Point-Supervised Camouflaged Object Detection   <br> <sup><sub>*Huafeng Chen, Dian Shao, Guangqian Guo, Shan Gao*</sub></sup>  | [Paper](https://arxiv.org/abs/2408.10777v1)\|[Code](https://github.com/2231122/PCOD) 
| 2023 | NeurIPS | `WS-SAM` | Weakly-Supervised Concealed Object Segmentation with SAM-based Pseudo Labeling and Multi-scale Feature Grouping   <br> <sup><sub>*Chunming He, Kai Li, Yachao Zhang, Guoxia Xu, Longxiang Tang, Yulun Zhang, Zhenhua Guo, Xiu Li*</sub></sup>  | [Paper](https://arxiv.org/abs/2305.11003)\|[Code](https://github.com/ChunmingHe/WS-SAM)
| 2023 | AAAI | `CRNet` | Weakly-Supervised Camouflaged Object Detection with Scribble Annotations <br> <sup><sub>*Ruozhen He, Qihua Dong, Jiaying Lin, Rynson W.H. Lau*</sub></sup>  | [Paper](https://ojs.aaai.org/index.php/AAAI/article/view/25156)\|[Code](https://github.com/dddraxxx/Weakly-Supervised-Camouflaged-Object-Detection-with-Scribble-Annotations)
</details>



<details>
    <summary><h3 id="34-COD"><span>3.4. Unsupervised COD</span></h3></summary>  

| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2025 | CVPR | `UCOD-DPL` | UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning   <br> <sup><sub>*Weiqi Yan, Lvhai Chen, Huaijia Kou, Shengchuan Zhang, Yan Zhang, Liujuan Cao*</sub></sup>  | [Paper](https://openaccess.thecvf.com/content/CVPR2025/html/Yan_UCOD-DPL_Unsupervised_Camouflaged_Object_Detection_via_Dynamic_Pseudo-label_Learning_CVPR_2025_paper.html)\|[Code](https://github.com/Heartfirey/UCOD-DPL) 
| 2025 | CVPR | `EASE` | Shift the Lens: Environment-Aware Unsupervised Camouflaged Object Detection  <br> <sup><sub>*Ji Du, Fangwei Hao, Mingyang Yu, Desheng Kong, Jiesheng Wu, Bin Wang, Jing Xu, Ping Li*</sub></sup>  | [Paper](https://openaccess.thecvf.com/content/CVPR2025/html/Du_Shift_the_Lens_Environment-Aware_Unsupervised_Camouflaged_Object_Detection_CVPR_2025_paper.html)\|[Code](https://github.com/xiaohainku/EASE) 
| 2025 | AAAI |  `SdalsNet` | SdalsNet: Self-Distilled Attention Localization and Shift Network for Unsupervised Camouflaged Object Detection  <br> <sup><sub>*Peiyao Shou, Yixiu Liu, Wei Wang, Yaoqi Sun, Zhigao Zheng, Shangdong Zhu, Chenggang Yan*</sub></sup>  | [Paper](https://ojs.aaai.org/index.php/AAAI/article/view/32742)\|Code
| 2023 | ICCVW | `UCOS-DA` | Unsupervised Camouflaged Object Segmentation as Domain Adaptation   <br> <sup><sub>*Yi Zhang; Chengyi Wu*</sub></sup>  | [Paper](https://openaccess.thecvf.com/content/ICCV2023W/OODCV/html/Zhang_Unsupervised_Camouflaged_Object_Segmentation_as_Domain_Adaptation_ICCVW_2023_paper.html)\|[Code](https://github.com/YeeZ93/UCOS-DA)
</details>



<details>
    <summary><h3 id="35-COD"><span>3.5. Referring COD</span></h3></summary>  

| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| --  | arXiv | `MLKG` | Large Model Based Referring Camouflaged Object Detection   <br> <sup><sub>*Shupeng Cheng, Ge-Peng Ji, Pengda Qin, Deng-Ping Fan, Bowen Zhou, Peng Xu*</sub></sup>  | [Paper](https://arxiv.org/abs/2311.17122)\|Code   
| 2025  | TIP | `UAT` | Uncertainty-Aware Transformer for Referring Camouflaged Object Detection  <br> <sup><sub>*Ranwan Wu, Tian-Zhu Xiang, Guo-Sen Xie, Rongrong Gao, Xiangbo Shu, Fang Zhao, Ling Shao*</sub></sup>  | [Paper](https://ieeexplore.ieee.org/abstract/document/11080234)\|[Code](https://github.com/CVL-hub/UAT)
| 2025 | WACV | `CIRCOD` | CIRCOD: Co-Saliency Inspired Referring Camouflaged Object Discovery  <br> <sup><sub>*Avi Gupta; Koteswar Rao Jerripothula; Tammam Tillo*</sub></sup>  | [Paper](https://www.computer.org/csdl/proceedings-article/wacv/2025/108300i320/25KnoFtUNIA)\|[Code](https://github.com/avigupta2798/CIRCOD/)    
| 2025  | TPAMI | `R2CNet` | Referring Camouflaged Object Detection <br> <sup><sub>*Xuying Zhang, Bowen Yin, Zheng Lin, Qibin Hou, Deng-Ping Fan, Ming-Ming Cheng*</sub></sup>  | [Paper](https://arxiv.org/abs/2306.07532)\|[Code](https://github.com/zhangxuying1004/RefCOD)   
| 2024 | ICME | `RPMA` | Reference Prompted Model Adaptation for Referring Camouflaged Object Detection   <br> <sup><sub>*Xuewei Liu; Shaofei Huang; Ruipu Wu; Hengyuan Zhao; Duo Xu; Xiaoming Wei, Jizhong Han, Si Liu*</sub></sup>  | [Paper](https://ieeexplore.ieee.org/abstract/document/10687557)\|Code
</details>



<details>
    <summary><h3 id="36-COD"><span>3.6. Zero-Shot COD</span></h3></summary>  

| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2025 | TPAMI | `CaMF` | Towards Real Zero-Shot Camouflaged Object Segmentation without Camouflaged Annotations      <br> <sup><sub>*Cheng Lei, Jie Fan, Xinran Li, Tian-Zhu Xiang, Ao Li, Ce Zhu, Le Zhang*</sub></sup>  | [Paper](https://arxiv.org/abs/2410.16953)\|[Code](https://github.com/R-LEI360725/ZSCOS-CaMF)
| 2025 | ACMMM | `--` |  From Language to Instance: Generative Visual Prompting for Zero-shot Camouflaged Object Detection   <br> <sup><sub>*Zihou Zhang, Hao Li, Zhengwei Yang, Zechao Hu, Liang Li, Zheng Wang*</sub></sup>  | Paper\|Code  
| 2024 | ACMMM | `MMCPF` | Chain of Visual Perception: Harnessing Multimodal Large Language Models for Zero-shot Camouflaged Object Detection    <br> <sup><sub>*Lv Tang, Peng-Tao Jiang, Zhihao Shen, Hao Zhang, Jinwei Chen, Bo Li*</sub></sup>  | [Paper](https://arxiv.org/abs/2311.11273)\|[Code](https://github.com/luckybird1994/MMCPF) 
| 2023 | TIP | `ZSCOD` | Zero-Shot Camouflaged Object Detection     <br> <sup><sub>*Haoran Li; Chun-Mei Feng; Yong Xu; Tao Zhou; Lina Yao; Xiaojun Chang*</sub></sup> | [Paper](https://ieeexplore.ieee.org/abstract/document/10234216)\|Code  
</details>



<details>
    <summary><h3 id="37-COD"><span>3.7. Multispectral COD</span></h3></summary>  

| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2025 | ACMMM DS | `MCOD` | MCOD: The First Challenging Benchmark for Multispectral Camouflaged Object Detection <br> <sup><sub>*Yang Li, Tingfa Xu, ShuYan Bai, Peifu Liu, Jianan Li*</sub></sup>  | [Paper](https://arxiv.org/abs/2509.15753)\|[Code](https://github.com/yl2900260-bit/MCOD)
</details>



<details>
    <summary><h3 id="38-COD"><span>3.8. Polarized COD</span></h3></summary>  

| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2025 | EAAI | `HIPFNet` | Polarization-based Camouflaged Object Detection with high-resolution adaptive fusion Network  <br> <sup><sub>*Xin Wang, Junfeng Xu, Jiajia Ding*</sub></sup>   | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S0952197625002453)\|[Code](https://github.com/CVhfut/HIPFNet)
| 2024 | EAAI | `IPNet` | IPNet: Polarization-based Camouflaged Object Detection via dual-flow network <br> <sup><sub>*Xin Wang, Jiajia Ding, Zhao Zhang, Junfeng Xu, Jun Gao*</sub></sup>   | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S0952197623014872)\|[Code](https://github.com/CVhfut/PCOD_1200) 
| 2023 | PRL | `PolarNet` | Polarization-based Camouflaged Object Detection <br> <sup><sub>*Xin Wang, Zhao Zhang, Jun Gao*</sub></sup>   | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S0167865523002532)\|[Code](https://github.com/CVhfut/Polar-COD)
</details>


</details>

----------------------------------------------------------------------------------------------------------------------

<details>
    <summary>
        <h2 id="4-Video-Camouflage-Detection">
            <span>4. Video Camouflage Detection</span>
        </h2>
    </summary>
    

<details>
    <summary><h3 id="41-COD"><span>4.1. Video Camouflaged Object Detection</span></h3></summary>    


| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2025 | arXiv | `--` | CamoVid60K: A Large-Scale Video Dataset for Moving Camouflaged Animals Understanding <br> <sup><sub>*Tuan-Anh Vu, Ziqiang Zheng, Chengyang Song, Qing Guo, Ivor Tsang, Sai-Kit Yeung*</sub></sup>  | [Paper](https://camovid.hkustvgd.com/)\|Code 
| 2025 | arXiv | `ZS-VCOS` | ZS-VCOS: Zero-Shot Video Camouflaged Object Segmentation By Optical Flow and Open Vocabulary Object Detection  <br> <sup><sub>*Wenqi Guo, Mohamed Shehata, Shan Du*</sub></sup>  | [Paper](https://arxiv.org/abs/2505.01431)\|[Code](https://github.com/weathon/vcos)
| 2025 | arXiv | `--` | MSVCOD: A Large-Scale Multi-Scene Dataset for Video Camouflage Object Detection <br> <sup><sub>*Shuyong Gao, Yu'ang Feng, Qishan Wang, Lingyi Hong, Xinyu Zhou, Liu Fei, Yan Wang, Wenqiang Zhang*</sub></sup>  | [Paper](https://arxiv.org/abs/2502.13859)\|Code 
| 2025 | NN | `--` | Disentangled self-supervised video camouflaged object detection and salient object detection   <br> <sup><sub>*Haoke Xiao, Lv Tang, Bo Li, Zhiming Luo, Shaozi Li*</sub></sup>  | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S0893608025009578?via%3Dihub)\|Code
| 2025 | TIP | `EMIP` | Explicit Motion Handling and Interactive Prompting for Video Camouflaged Object Detection   <br> <sup><sub>*Xin Zhang, Tao Xiao, Gepeng Ji, Xuan Wu, Keren Fu, Qijun Zhao*</sub></sup>  | [Paper](https://arxiv.org/abs/2403.01968)\|[Code](https://github.com/zhangxin06/EMIP)  
| 2025 | VI | `SAM2-VCOS` | When SAM2 meets video camouflaged object segmentation: a comprehensive evaluation and adaptation   <br> <sup><sub>*Yuli Zhou, Guolei Sun, Yawei Li, Guo-Sen Xie, Luca Benini, Ender Konukoglu*</sub></sup>  | [Paper](https://link.springer.com/article/10.1007/s44267-025-00082-1)\|[Code](https://github.com/zhoustan/SAM2-VCOS)  
| 2024 | TPAMI  | `ZoomNeXt` | ZoomNeXt: A Unified Collaborative Pyramid Network for Camouflaged Object Detection   <br> <sup><sub>*Youwei Pang, Xiaoqi Zhao, Tian-Zhu Xiang, Lihe Zhang, Huchuan Lu*</sub></sup>  | [Offl.](https://ieeexplore.ieee.org/document/10568374)\|[arXiv](https://arxiv.org/abs/2310.20208)\|[Code](https://github.com/lartpang/ZoomNeXt)  
| 2024 | IJCV | `RCFF` | The Right Spin: Learning Object Motion from Rotation-Compensated Flow Fields     <br> <sup><sub>*Pia Bideau, Erik Learned-Miller, Cordelia Schmid, Karteek Alahari*</sub></sup> | [Offl.](https://link.springer.com/article/10.1007/s11263-023-01859-x)\|[arXiv](https://arxiv.org/abs/2203.00115)
| 2024 | TMM | `IMEX` | Implicit-Explicit Motion Learning for Video Camouflaged Object Detection    <br> <sup><sub>*Wenjun Hui; Zhenfeng Zhu; Guanghua Gu; Meiqin Liu; Yao Zhao*</sub></sup> | [Paper](https://ieeexplore.ieee.org/abstract/document/10430451)\|Code 
| 2024 | CVPR  | `TSP-SAM` | Endow SAM with Keen Eyes: Temporal-spatial Prompt Learning for Video Camouflaged Object Detection    <br> <sup><sub>*Wenjun Hui, Zhenfeng Zhu, Shuai Zheng, Yao Zhao*</sub></sup> | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Hui_Endow_SAM_with_Keen_Eyes_Temporal-spatial_Prompt_Learning_for_Video_CVPR_2024_paper.html)\|[Code](https://github.com/WenjunHui1/TSP-SAM)
| 2024 | CVPRW | `SAM-PM`| SAM-PM: Enhancing Video Camouflaged Object Detection using Spatio-Temporal Attention  <br> <sup><sub>*Muhammad Nawfal Meeran, Gokul Adethya T, Bhanu Pratyush Mantha*</sub></sup> | [Paper](https://openaccess.thecvf.com/content/CVPR2024W/PVUW/html/Meeran_SAM-PM_Enhancing_Video_Camouflaged_Object_Detection_using_Spatio-Temporal_Attention_CVPRW_2024_paper.html)\|[Code](https://github.com/SpiderNitt/SAM-PM) 
| 2024 | TCSVT |  `STM` | A Weakly-supervised Cross-domain Query Framework for Video Camouflage Object Detection  <br> <sup><sub>*Zelin Lu; Liang Xie; Xing Zhao; Binwei Xu; Haoran Liang; Ronghua Liang*</sub></sup>  | [Paper](https://ieeexplore.ieee.org/abstract/document/10700777)\|Code 
| 2024 | ICASSP | `TMNet` | Tokenmotion: Motion-Guided Vision Transformer for Video Camouflaged Object Detection VIA Learnable Token Selection   <br> <sup><sub>*Zifan Yu; Erfan Bank Tavakoli; Meida Chen; Suya You; Raghuveer Rao; et al*</sub></sup>  | [Paper](https://ieeexplore.ieee.org/document/10447329)\|Code 
| 2023 | ICCV | `-` | The Making and Breaking of Camouflage    <br> <sup><sub>*Hala Lamdouar, Weidi Xie, Andrew Zisserman*</sub></sup> | [Paper](https://arxiv.org/abs/2309.03899)\|[Code](https://github.com/hlamdouar/CAMEVAL) 
| 2022 | CVPR | `SLTNet` | Implicit Motion Handling for Video Camouflaged Object Detection <br> <sup><sub>*Xuelian Cheng, Huan Xiong, Deng-Ping Fan, et al.*</sub></sup> | [Paper](https://dengpingfan.github.io/papers/[2022][CVPR]VCOD_MoCA-Mask.pdf)\|[Code](https://github.com/XuelianCheng/SLT-Net) 
| 2022 | CVPR | `QSDI` | A Deeper Dive Into What Deep Spatiotemporal Networks Encode: Quantifying Static vs. Dynamic Information      <br> <sup><sub>*Matthew Kowal, Mennatullah Siam, Md Amirul Islam, Neil D. B. Bruce, Richard P. Wildes, Konstantinos G. Derpanis*</sub></sup>  | [Offl.](https://openaccess.thecvf.com/content/CVPR2022/html/Kowal_A_Deeper_Dive_Into_What_Deep_Spatiotemporal_Networks_Encode_Quantifying_CVPR_2022_paper.html)\|[arXiv](https://arxiv.org/abs/2211.01783)\|[Code](https://github.com/YorkUCVIL/Static-Dynamic-Interpretability/)\|[Proj](https://yorkucvil.github.io/Static-Dynamic-Interpretability/)  
| 2022 | NeurIPS | `OCLR` | Segmenting Moving Objects via an Object-Centric Layered Representation    <br> <sup><sub>*Junyu Xie, Weidi Xie, Andrew Zisserman*</sub></sup> | [Paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/b37aa1d677970f2f56d0d17410c52b3b-Paper-Conference.pdf)\|[Code](https://github.com/Jyxarthur/OCLR_model)
| 2022 | TPAMI | `-` | EM-driven unsupervised learning for efficient motion segmentation      <br> <sup><sub>*Etienne Meunier, AnaÃ¯s Badoual, Patrick Bouthemy*</sub></sup> | [Paper](https://arxiv.org/abs/2201.02074)\|[Code](https://github.com/Etienne-Meunier-Inria/EM-Flow-Segmentation) 
| 2021 | ICCV | `MG` | Self-supervised Video Object Segmentation by Motion Grouping      <br> <sup><sub>*Charig Yang, Hala Lamdouar, Erika Lu, Andrew Zisserman, Weidi Xie*</sub></sup>  | [Paper](https://openaccess.thecvf.com/content/ICCV2021/html/Yang_Self-Supervised_Video_Object_Segmentation_by_Motion_Grouping_ICCV_2021_paper.html)\|[Code](https://charigyang.github.io/motiongroup/)\|[Proj](https://charigyang.github.io/motiongroup/)  
| 2021 | BMVC | `SIMO` | Segmenting Invisible Moving Objects       <br> <sup><sub>*Hala Lamdouar, Weidi Xie, Andrew Zisserman*</sub></sup> | [Paper](https://www.bmvc2021-virtualconference.com/assets/papers/0056.pdf)\|[Proj](https://www.robots.ox.ac.uk/~vgg/research/simo/)  
| 2020 | ACCV | `-` | Betrayed by Motion: Camouflaged Object Discovery via Motion Segmentation <br> <sup><sub>*Hala Lamdouar, Charig Yang, Weidi Xie, Andrew Zisserman*</sub></sup>   | [Paper](https://arxiv.org/abs/2011.11630)\|[Code](https://github.com/hlamdouar/MoCA/)\|[Data](https://www.robots.ox.ac.uk/~vgg/data/MoCA/)  
| 2018 | TIP | `FWFC` | A Fusion Framework for Camouflaged Moving Foreground Detection in the Wavelet Domain <br><sup><sub>*Shuai Li, Dinei Florencio, Wanqing Li, Yaqin Zhao, Chris Cook*</sub></sup>   | [Paper](https://arxiv.org/abs/1804.05984)\|[Code](https://sites.google.com/view/wanqingli/data-sets/uow-camo?authuser=0)    |
| 2017 | IJCV | `modiPNN` | Partially Camouflaged Object Tracking using Modified Probabilistic Neural Network and Fuzzy Energy based Active Contour    <br><sup><sub>*Ajoy Mondal, Susmita Ghosh, Ashish Ghosh*</sub></sup>  | [Paper](https://link.springer.com/article/10.1007/s11263-016-0959-5)\|Code   |
| 2016 | ECCV | `--` | Itâ€™s Moving! A Probabilistic Model for Causal Motion Segmentation in Moving Camera Videos <br> <sup><sub>*Pia Bideau, Erik Learned-Miller*</sub></sup>  | [Paper](https://link.springer.com/chapter/10.1007/978-3-319-46484-8_26)\|[Code](https://www.user.tu-berlin.de/pbideau/motionSegmentation/index.html)
</details>

</details>

----------------------------------------------------------------------------------------------------------------------

<details>
    <summary>
        <h2 id="5-Camouflage-Segmentation">
            <span>5. Camouflage Segmentation</span>
        </h2>
    </summary>


### 5.1. Camouflage Object Segmentation

| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |


<details>
    <summary><h3 id="52-COD"><span>5.2. Camouflaged Instance Segmentation</span></h3></summary>    


| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2024 | MM | `TPNet` | Text-prompt Camouflaged Instance Segmentation with Graduated Camouflage Learning  <br> <sup><sub>*Zhentao He, Changqun Xia, Shengye Qiao, Jia Li*</sub></sup>  | [Paper](https://dl.acm.org/doi/10.1145/3664647.3681132)\|[Code](https://github.com/zertow/TPNet) 
| 2024 | MM | `AQSFormer` | Adaptive Query Selection for Camouflaged Instance Segmentation   <br> <sup><sub>*Bo Dong, Pichao Wang, Hao Luo, Fan Wang*</sub></sup>  | [Paper](https://dl.acm.org/doi/10.1145/3664647.3680749)\|Code 
| 2024 | ApplInt | `MSPNet` | Multi-scale pooling learning for camouflaged instance segmentation   <br> <sup><sub>*Chen Li, Ge Jiao, Guowen Yue, Rong He & Jiayu Huang*</sub></sup>  | [Paper](https://link.springer.com/article/10.1007/s10489-024-05369-2)\|[Code](https://github.com/another-u/MSPNet-main) 
| 2023 | MM | `UQFormer` | A Unified Query-based Paradigm for Camouflaged Instance Segmentation  <br> <sup><sub>*Do Dong, Jialun Pei, Rongrong Gao, Tian-Zhu Xiang, Shuo Wang, Huan Xiong*</sub></sup>  | [Paper](https://arxiv.org/abs/2308.07392)\|[Code](https://github.com/dongbo811/UQFormer)
| 2023 | CVPR | `DCNet` | Camouflaged Instance Segmentation via Explicit De-camouflaging  <br> <sup><sub>*Naisong Luo, Yuwen Pan, Rui Sun, Tianzhu Zhang, Zhiwei Xiong, Feng Wu*</sub></sup>  | [Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_Camouflaged_Instance_Segmentation_via_Explicit_De-Camouflaging_CVPR_2023_paper.pdf)\|[Code](https://github.com/USTCL/DCNet)
| 2023 | arXiv | `-` | Leveraging Open-Vocabulary Diffusion to Camouflaged Instance Segmentation  <br> <sup><sub>*Tuan-Anh Vu, Duc Thanh Nguyen, Qing Guo, Binh-Son Hua, Nhat Minh Chung, Ivor W. Tsang, Sai-Kit Yeung*</sub></sup>  | [Paper](https://arxiv.org/abs/2312.17505)\|Code 
| 2022 | ECCV | `OSFormer` | OSFormer: One-Stage Camouflaged Instance Segmentation with Transformers    <br> <sup><sub>*Jialun Pei, Tianyang Cheng, Deng-Ping Fan, et al.*</sub></sup> | [Paper](https://arxiv.org/abs/2207.02255)\|[Code](https://github.com/PJLallen/OSFormer)
| 2022 | TIP | `CFL` | Camouflaged Instance Segmentation In-The-Wild: Dataset, Method, and Benchmark Suite <br> <sup><sub>*Trung-Nghia Le, Yubo Cao, Tan-Cong Nguyen, et al.*</sub></sup> | [Paper](https://arxiv.org/abs/2103.17123)\|[Proj](https://sites.google.com/view/ltnghia/research/camo_plus_plus)  
| 2021 | AAAI | `-` | CamouFinder: Finding Camouflaged Instances in Images <br><sup><sub>*Trung-Nghia Le, Vuong Nguyen, Cong Le, et al.*</sub></sup> | [Paper](https://ojs.aaai.org/index.php/AAAI/article/view/18015)\|[Video](https://www.youtube.com/watch?v=RI4nt5MDmwE&ab_channel=TrungNgh%C4%A9aL%C3%AA)
</details>



<details>
    <summary><h3 id="53-COD"><span>5.3. Open-Vocabulary COS</span></h3></summary>    


| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2024  | ECCV | `OVCoser` | Open-Vocabulary Camouflaged Object Segmentation <br> <sup><sub>*Youwei Pang, Xiaoqi Zhao, Jiaming Zuo, Lihe Zhang, Huchuan Lu*</sub></sup>   | [Paper](https://arxiv.org/abs/2311.11241)\|[Code](https://github.com/lartpang/OVCamo)
| 2023  | arXiv | `-` | Leveraging Open-Vocabulary Diffusion to Camouflaged Instance Segmentation  <br> <sup><sub>*Tuan-Anh Vu, Duc Thanh Nguyen, Qing Guo, Binh-Son Hua, Nhat Minh Chung, Ivor W. Tsang, Sai-Kit Yeung*</sub></sup>  | [Paper](https://arxiv.org/abs/2312.17505)\|Code 
</details>



</details>

----------------------------------------------------------------------------------------------------------------------


<details>
    <summary><h2 id="6-Camouflage-Generation"><span>6. Camouflage Generation</span></h2></summary>

| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2025 | CVPR | `CO+RE-BG` | Camouflage Anything: Learning to Hide using Controlled Out-painting and Representation Engineering   <br> <sup><sub>*Biplab Das, Viswanath Gopalakrishnan*</sub></sup>  | [Paper](https://openaccess.thecvf.com/content/CVPR2025/html/Das_Camouflage_Anything_Learning_to_Hide_using_Controlled_Out-painting_and_Representation_CVPR_2025_paper.html)\|Code
| 2024 | CVPR | `LAKE-RED` | LAKE-RED: Camouflaged Images Generation by Latent Background Knowledge Retrieval-Augmented Diffusion   <br> <sup><sub>*Pancheng Zhao, Peng Xu, Pengda Qin, Deng-Ping Fan, Zhicheng Zhang, Guoli Jia, Bowen Zhou, Jufeng Yang*</sub></sup>  | [Paper](https://arxiv.org/abs/2404.00292)\|[Code](https://github.com/PanchengZhao/LAKE-RED) 
| 2023 | AIR | `CamDiff` | CamDiff: Camouflage Image Augmentation via Diffusion Model   <br> <sup><sub>*Xue-Jing Luo, Shuo Wang, Zongwei Wu, Christos Sakaridis, Yun Cheng, Deng-Ping Fan, Luc Van Gool*</sub></sup> | [Paper](https://arxiv.org/abs/2304.05469)\|[Code](https://github.com/drlxj/CamDiff) 
| 2022 | CVPR | `GANmouflage` | GANmouflage: 3D Object Nondetection with Texture Fields   <br> <sup><sub>*Rui Guo, Jasmine Collins, Oscar de Lima, Andrew Owens*</sub></sup>  | [Paper](https://arxiv.org/abs/2201.07202)\|[Proj](https://rrrrrguo.github.io/ganmouflage/)
| 2022 | TMM | `LCG-Net` | Location-Free Camouflage Generation Network  <br> <sup><sub>*Yangyang Li, Wei Zhai, Yang Cao, Zheng-jun Zha*</sub></sup> | [Paper](https://arxiv.org/abs/2203.09845)\|[Code](https://github.com/Tale17/LCG-Net) 
| 2020 | AAAI | `-` | Deep Camouflage Images        <br><sup><sub>*Qing Zhang, Gelin Yin, Yongwei Nie, Wei-Shi Zheng*</sub></sup>       | [Paper](https://ojs.aaai.org//index.php/AAAI/article/view/6981)\|[Code](https://github.com/hirokic5/Pytorch_CamouflageImages)
</details>





----------------------------------------------------------------------------------------------------------------------

<details>
    <summary><h2 id="7-Camouflage-Tracking"><span>7. Camouflage Tracking</span></h2></summary>

| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2025 | ACMMM DS | `HiPTrack-MLS` | Camouflaged Object Tracking: A Benchmark <br> <sup><sub>*Xiaoyu Guo, Pengzhi Zhong, Hao Zhang, Defeng Huang, Huikai Shao, Qijun Zhao, Shuiwang Li*</sub></sup>  | [Paper](https://arxiv.org/abs/2408.13877)\|[Code](https://github.com/openat25/HIPTrack-MLS)
</details>

----------------------------------------------------------------------------------------------------------------------


<details>
    <summary><h2 id="8-Other-Related"><span>8. Other Related</span></h2></summary>

| **Year** | **Pub.** | **Method** | **Title** | **Links** |
| :------: | :------: | :-------: | :--------: | :-------: |
| 2025 | TCSVT | `DAD` | Towards Complex Backgrounds: A Unified Difference-Aware Decoder for Binary Segmentation    <br> <sup><sub>*Jiepan Li; Wei He; Fangxiao Lu; Hongyan Zhang*</sub></sup>  | [Paper](https://ieeexplore.ieee.org/document/11175179)\|[Code](https://github.com/Henryjiepanli/DAD)   
| 2025 | AAAI | `FOCUS` | FOCUS: Towards Universal Foreground Segmentation   <br> <sup><sub>*Zuyao You, Lingyu Kong, Lingchen Meng, Zuxuan Wu*</sub></sup>  | [Paper](https://arxiv.org/abs/2501.05238)\|[Code](https://geshang777.github.io/focus.github.io/)  
| 2024 | ICML | `Spider` | Spider: A Unified Framework for Context-dependent Concept Understanding    <br> <sup><sub>*Xiaoqi Zhao, Youwei Pang, Wei Ji, Baicheng Sheng, Jiaming Zuo, Lihe Zhang, Huchuan Lu*</sub></sup>  | [Paper](https://arxiv.org/abs/2405.01002)\|[Code](https://github.com/Xiaoqi-Zhao-DLUT/Spider-UniCDSeg)  
| 2024 | IJCV | `GateNetv2` | Towards Diverse Binary Segmentation via A Simple yet General Gated Network   <br> <sup><sub>*Xiaoqi Zhao, Youwei Pang, Lihe Zhang, Huchuan Lu, Lei Zhang*</sub></sup>  | [Paper](https://arxiv.org/abs/2303.10396)\|[Code](https://github.com/Xiaoqi-Zhao-DLUT/GateNet-RGB-Saliency)\|[Res.](https://github.com/Xiaoqi-Zhao-DLUT/Awesome-Unified-Context-dependent-Concept-Segmentation) 
| 2022 | CVPR | `DTA` | DTA: Physical Camouflage Attacks using Differentiable Transformation Network     <br> <sup><sub>*Naufal Suryanto, Yongsu Kim, Hyoeun Kang, et al.*</sub></sup> | [Paper](https://arxiv.org/abs/2203.09831)\|Code
</details>

----------------------------------------------------------------------------------------------------------------------

## Datasets
<sup>Note: Ann. Img. = Number of frames annotated in the dataset; BBbox = Bounding box; Pix. = Pixel-level mask; Ins. = Instance mask; Cate. = Category.</sup>

#### - Image COD

| **Name** | **Year** | **Pub.** | **Links** | **Type** | **Img.(Camo.)** | **BBbox** | **Pix.** | **Ins.** | **Comments**
| :------: | :------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: |
[USC12K](https://github.com/ssecv/USCNet) | 2025 | ICCV | [Paper](https://arxiv.org/abs/2412.10943) | Img | 12000 |  | &check; |  | <sup><sub>Unconstrained salient & camouflaged object detection</sub></sup> 
[R2C7K](https://github.com/zhangxuying1004/RefCOD) | 2025 | TPAMI | [Paper](https://github.com/zhangxuying1004/RefCOD) | Img | 5015/1600(Ref) |  | &check; |  | <sup><sub>Referring COD</sub></sup> | 
[PlantCamo](https://github.com/yjybuaa/PlantCamo) | 2025 | AIR | [Paper](https://arxiv.org/pdf/2410.17598) | Img | 1250 | &check; | &check; | &check; | <sup><sub>Plant COD</sub></sup>  |  
[CoCOD8K](https://github.com/zc199823/BBNet--CoCOD) | 2024 | TNNLS | [Paper](https://arxiv.org/abs/2310.04253) | Img | 8528 |  | &check; | | <sup><sub>Co-COD</sub></sup>  | 
[ACOD-12K](https://github.com/Kki2Eve/RISNet) | 2024 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Depth-Aware_Concealed_Crop_Detection_in_Dense_Agricultural_Scenes_CVPR_2024_paper.pdf) | Img | 6092 | &check; | &check; | | <sup><sub>RGB-D COD (Crop)</sub></sup> 
[ACOD2K](https://github.com/syxvision/FDNet) | 2023 | ICME | [Paper](https://arxiv.org/abs/2307.03943) | Img | 1500 |  | &check; | | <sup><sub>Artificial camouflaged object</sub></sup>  
[CAM-LDR](https://github.com/JingZhang617/COD-Rank-Localize-and-Segment) | 2023 | TCSVT | [Paper](https://arxiv.org/abs/2205.11333) | Img | 4040 | | | | <sup><sub>Camo ranking (fixation & ranking)</sub></sup>  
[CAMO++](https://sites.google.com/view/ltnghia/research/camo_plus_plus?authuser=0) | 2021 | TIP | [Paper](https://arxiv.org/abs/2103.17123) | Img | 2700 | &check; | &check; | &check; |  <sup><sub>Instance seg.</sub></sup>  
[NC4K](https://github.com/JingZhang617/COD-Rank-Localize-and-Segment) | 2021 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Lv_Simultaneously_Localize_Segment_and_Rank_the_Camouflaged_Objects_CVPR_2021_paper.pdf) | Img | 4121 | &check; | &check; | &check; |
[COD10K](http://dpfan.net/camouflage/) | 2020 | CVPR | [Paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Fan_Camouflaged_Object_Detection_CVPR_2020_paper.pdf) | Img | 5066 | &check; | &check; | &check; |
[CAMO](https://sites.google.com/view/ltnghia/research/camo) | 2019 | CVIU | [Paper](http://www.dgcv.nii.ac.jp/Publications/Papers/2019/cviu2019.pdf) | Img | 1250 |   | &check; |   |
[CPD1K](https://github.com/xfflyer/Camouflaged-people-detection) | 2018 | SPL | [Paper](https://ieeexplore.ieee.org/document/8336933)  | Img | 1000 |   | &check; |   | 
[CHAMELEON](https://www.polsl.pl/rau6/chameleon-database-animal-camouflage-analysis/) | 2017 | â€” | [Webpage](https://www.polsl.pl/rau6/chameleon-database-animal-camouflage-analysis/) | Img | 76 |   | &check; |   | 


#### - Weakly-Supervised Image COD

| **Name** | **Year** | **Pub.** | **Links** | **Type** | **Img.(Camo.)** | 
| :------: | :------: | :-------: | :-------: | :-------: | :-------: |
[P-COD](https://github.com/2231122/PCOD) | 2024 | ECCV | [Paper](https://arxiv.org/abs/2408.10777) | Point | 4040 | 
[S-COD](https://github.com/dddraxxx/Weakly-Supervised-Camouflaged-Object-Detection-with-Scribble-Annotations) | 2023 | AAAI | [Paper](https://arxiv.org/abs/2207.14083) | Scribble | 4040 | 


#### - Visual-Language Dataset

| **Name** | **Year** | **Pub.** | **Links** | **Img.(Camo.)** | **BBbox** | **Pix.** | **Ins.** | **Comments**
| :------: | :------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: |
[MM-CamObj](https://github.com/JCruan519/MM-CamObj) | 2025 | AAAI | [Paper](https://ojs.aaai.org/index.php/AAAI/article/view/32723) | 11363 |   | &check; |  | <sup><sub>CamObj-Align: image-text pairs; CamObj-Instruct: images and conversations with diverse instructions</sub></sup> |
[COD-TAX](https://github.com/lyu-yx/ACUMEN) | 2024 | ECCV | [Paper](https://arxiv.org/abs/2408.12086) | -- |  | &check; |  | <sup><sub>Obj masks with textual descriptions and attribute contributions</sub></sup> | 
[OVCamo](https://github.com/lartpang/OVCamo) | 2024 | ECCV | [Paper](https://arxiv.org/abs/2311.11241) | 11483 |  | &check; |  |  <sup><sub>Open-vocabulary seg. (obj. classes & masks)</sub></sup>|


#### - Video COD

| **Dataset** | **Year** | **Pub.** | **Links** | **Type** | **Clips/Ann.Img.** | **BBbox** | **Pix.** | **Ins.** | **Cate.** |**Comments** 
| :------: | :------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: |
[CamoVid60K](https://camovid.hkustvgd.com/) | 2025 | arXiv | [Paper](https://camovid.hkustvgd.com/) | Video |  218/62,774 | &check; | &check; | | &check; | 
MVCOD  | 2025 | arXiv | [Paper](https://arxiv.org/abs/2502.13859) | Video | 162/9,486 | &check; | &check; | &check; | &check; | | 
[MoCA-Mask](https://xueliancheng.github.io/SLT-Net-project/) | 2022 | CVPR | [Paper](https://arxiv.org/abs/2203.07363) | Video | 87/4,691 | &check; | &check; |   | &check; |   | 
[MoCA](https://www.robots.ox.ac.uk/~vgg/data/MoCA/) | 2020 | ACCV | [Paper](https://openaccess.thecvf.com/content/ACCV2020/html/Lamdouar_Betrayed_by_Motion_Camouflaged_Object_Discovery_via_Motion_Segmentation_ACCV_2020_paper.html) | Video | 141/7,617 | &check; |  |  |  |   | 
[CAMO UOW](https://sites.google.com/view/wanqingli/data-sets/uow-camo?authuser=0) | 2018 | TIP | [Paper](https://ieeexplore.ieee.org/document/8344427) | Video | 10/- |  | &check; |  |  | <sup><sub>Cate.: human</sub></sup>  
[CAD](https://www.user.tu-berlin.de/pbideau/motionSegmentation/index.html) | 2016 | ECCV | [Paper](https://link.springer.com/chapter/10.1007/978-3-319-46484-8_26) | Video | 9/191 |   | &check; |   |   | <sup><sub>Camouflaged Animal Dataset (CAD)</sub></sup>  


#### - Other Related Dataset 

| **Name** | **Year** | **Pub.** | **Links** | **Type** | **Img.(Camo.)** | **Ann.** | **Comments**
| :------: | :------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: |
[IOCfish5K](https://github.com/GuoleiSun/Indiscernible-Object-Counting) | 2023 | CVPR | [Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Indiscernible_Object_Counting_in_Underwater_Scenes_CVPR_2023_paper.html) | Img | 5637 | Point/Counting | <sup><sub>Indiscernible Object Counting</sub></sup>  
[CDS2K](https://github.com/DengPingFan/CSU) | 2023 | VI | [Paper](https://arxiv.org/abs/2304.11234) | Img | 2492 | BBbox+Pix. | <sup><sub>Defect seg. dataset</sub></sup>  


## Reference

- [SINet-V2/AWESOME_COD_LIST](https://github.com/GewelsJI/SINet-V2/blob/main/AWESOME_COD_LIST.md)
- [visionxiang/awesome-camouflaged-object-detection](https://github.com/visionxiang/awesome-camouflaged-object-detection)
- [ChunmingHe/awesome-concealed-object-segmentation](https://github.com/ChunmingHe/awesome-concealed-object-segmentation)

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Awesome-COD/awesome-cod&type=Date)](https://www.star-history.com/#Awesome-COD/awesome-cod&Date)
